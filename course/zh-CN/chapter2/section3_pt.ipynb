{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB1_Re-_UZaQ"
      },
      "source": [
        "# 模型 (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrIFULaiUZaS"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqCqp85EUZaT"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1j3H9MyUZaU"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "# Building the config\n",
        "config = BertConfig()\n",
        "\n",
        "# Building the model from the config\n",
        "model = BertModel(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTjmEA7dUZaV",
        "outputId": "c372a12a-83b3-48c5-f66b-3651057ade96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  [...]\n",
              "  \"hidden_size\": 768,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  [...]\n",
              "}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF8HJD_dUZaW"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "config = BertConfig()\n",
        "model = BertModel(config)\n",
        "\n",
        "# Model is randomly initialized!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3gBL1mD5UZaX",
        "outputId": "a10ee8c3-4d86-423b-de57-c2974b66263b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 4.4496e-01,  4.8276e-01,  2.7797e-01,  ..., -5.4032e-02,\n",
            "           3.9393e-01, -9.4770e-02],\n",
            "         [ 2.4943e-01, -4.4093e-01,  8.1772e-01,  ..., -3.1917e-01,\n",
            "           2.2992e-01, -4.1172e-02],\n",
            "         [ 1.3668e-01,  2.2518e-01,  1.4502e-01,  ..., -4.6915e-02,\n",
            "           2.8224e-01,  7.5566e-02],\n",
            "         [ 1.1789e+00,  1.6738e-01, -1.8187e-01,  ...,  2.4671e-01,\n",
            "           1.0441e+00, -6.1972e-03]],\n",
            "\n",
            "        [[ 3.6436e-01,  3.2464e-02,  2.0258e-01,  ...,  6.0110e-02,\n",
            "           3.2451e-01, -2.0996e-02],\n",
            "         [ 7.1866e-01, -4.8725e-01,  5.1740e-01,  ..., -4.4012e-01,\n",
            "           1.4553e-01, -3.7545e-02],\n",
            "         [ 3.3223e-01, -2.3271e-01,  9.4876e-02,  ..., -2.5268e-01,\n",
            "           3.2172e-01,  8.1085e-04],\n",
            "         [ 1.2523e+00,  3.5754e-01, -5.1320e-02,  ..., -3.7840e-01,\n",
            "           1.0526e+00, -5.6255e-01]],\n",
            "\n",
            "        [[ 2.4042e-01,  1.4718e-01,  1.2110e-01,  ...,  7.6062e-02,\n",
            "           3.3564e-01,  2.8262e-01],\n",
            "         [ 6.5701e-01, -3.2787e-01,  2.4968e-01,  ..., -2.5919e-01,\n",
            "           2.0175e-01,  3.3275e-01],\n",
            "         [ 2.0160e-01,  1.5783e-01,  9.8970e-03,  ..., -3.8850e-01,\n",
            "           4.1307e-01,  3.9732e-01],\n",
            "         [ 1.0175e+00,  6.4387e-01, -7.8147e-01,  ..., -4.2109e-01,\n",
            "           1.0925e+00, -4.8456e-02]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.6856,  0.5262,  1.0000,  ...,  1.0000, -0.6112,  0.9971],\n",
            "        [-0.6055,  0.4997,  0.9998,  ...,  0.9999, -0.6753,  0.9769],\n",
            "        [-0.7702,  0.5447,  0.9999,  ...,  1.0000, -0.4655,  0.9894]],\n",
            "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "\n",
        "model = BertModel.from_pretrained(\"bert-base-cased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "\n",
        "\n",
        "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]\n",
        "\n",
        "encoded_sequences = [\n",
        "    [101, 7592, 999, 102],\n",
        "    [101, 4658, 1012, 102],\n",
        "    [101, 3835, 999, 102],\n",
        "]\n",
        "\n",
        "import torch\n",
        "\n",
        "model_inputs = torch.tensor(encoded_sequences)\n",
        "\n",
        "output = model(model_inputs)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVCxZ8u1UZaY"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"directory_on_my_computer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yIPkjX8RUZaZ"
      },
      "outputs": [],
      "source": [
        "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZVDzLR0XUZaa"
      },
      "outputs": [],
      "source": [
        "encoded_sequences = [\n",
        "    [101, 7592, 999, 102],\n",
        "    [101, 4658, 1012, 102],\n",
        "    [101, 3835, 999, 102],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bOdVNoXBUZab"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "model_inputs = torch.tensor(encoded_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tGxde-Q2UZac",
        "outputId": "0666c35c-2e44-44d4-9b8d-6c256427453b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-649e668bd026>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "output = model(model_inputs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "模型 (PyTorch)",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}